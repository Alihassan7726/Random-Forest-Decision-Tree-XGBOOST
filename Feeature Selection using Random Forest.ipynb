{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in data science we have hundreds or even millions of features and we want a way to create a model that only includes the most important features. This has three benefits. First, we make our model more simple to interpret. Second, we can reduce the variance of the model, and therefore overfitting. Finally, we can reduce the computational cost (and time) of training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create a list of feature names\n",
    "feat_labels = ['Sepal Length','Sepal Width','Petal Length','Petal Width']\n",
    "\n",
    "# Create X from the features\n",
    "X = iris.data\n",
    "\n",
    "# Create y from output\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the features\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the target data\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 40% test and 60% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sepal Length', 0.11024282328064558)\n",
      "('Sepal Width', 0.016255033655398383)\n",
      "('Petal Length', 0.45028123999239505)\n",
      "('Petal Width', 0.42322090307156096)\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf2 = DecisionTreeClassifier()\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (4 Features) Model\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel will select those features which importance is greater than the mean importance of all the features by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(n_estimators=10000, n_jobs=-1,\n",
       "                                                 random_state=0),\n",
       "                threshold=0.15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf, threshold=0.15)\n",
    "sfm2 = SelectFromModel(clf2 , threshold = 0.15)\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=DecisionTreeClassifier(), threshold=0.15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm2.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petal Length\n",
      "Petal Width\n",
      "----------------\n",
      "Petal Length\n",
      "Petal Width\n"
     ]
    }
   ],
   "source": [
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n",
    "print(\"----------------\")\n",
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm2.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Petal Length'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5, 1.6],\n",
       "       [1.6, 0.2],\n",
       "       [5.1, 1.9],\n",
       "       [4.2, 1.3],\n",
       "       [3.6, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.4],\n",
       "       [6. , 1.8],\n",
       "       [1.5, 0.2],\n",
       "       [1.1, 0.1],\n",
       "       [5.3, 1.9],\n",
       "       [4.2, 1.2],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [4.9, 1.5],\n",
       "       [1.5, 0.2],\n",
       "       [5.1, 1.8],\n",
       "       [3. , 1.1],\n",
       "       [1.4, 0.3],\n",
       "       [4.5, 1.5],\n",
       "       [6.1, 2.5],\n",
       "       [4.2, 1.3],\n",
       "       [1.4, 0.1],\n",
       "       [5.9, 2.1],\n",
       "       [5.7, 2.3],\n",
       "       [5.8, 2.2],\n",
       "       [5.6, 2.1],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [5.1, 2. ],\n",
       "       [5.7, 2.1],\n",
       "       [1.3, 0.3],\n",
       "       [5.4, 2.3],\n",
       "       [1.4, 0.2],\n",
       "       [5. , 2. ],\n",
       "       [5.4, 2.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [5.8, 1.6],\n",
       "       [1.4, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [4. , 1.3],\n",
       "       [5.9, 2.3],\n",
       "       [6.6, 2.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.5, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [1.2, 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [4.3, 1.3],\n",
       "       [1.5, 0.4],\n",
       "       [6.9, 2.3],\n",
       "       [3.3, 1. ],\n",
       "       [6.4, 2. ],\n",
       "       [4.4, 1.4],\n",
       "       [1.5, 0.1],\n",
       "       [4.8, 1.8],\n",
       "       [1.2, 0.2],\n",
       "       [6.7, 2. ],\n",
       "       [1.5, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [6.1, 1.9],\n",
       "       [1.4, 0.2],\n",
       "       [5.6, 2.4],\n",
       "       [4.1, 1.3],\n",
       "       [3.9, 1.2],\n",
       "       [3.5, 1. ],\n",
       "       [5.3, 2.3],\n",
       "       [5.2, 2.3],\n",
       "       [4.9, 1.5],\n",
       "       [5. , 1.7],\n",
       "       [1.6, 0.2],\n",
       "       [3.7, 1. ],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 1.9],\n",
       "       [1.5, 0.2],\n",
       "       [4.6, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4.8, 1.8],\n",
       "       [4.4, 1.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [5.6, 1.8],\n",
       "       [4.1, 1. ],\n",
       "       [6.7, 2.2],\n",
       "       [1.4, 0.2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_important_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10000, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
